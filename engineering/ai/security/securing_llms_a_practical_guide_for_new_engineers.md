# Безопасность LLM: практическое руководство для начинающих инженеров

Securing LLMs: A Practical Guide for New Engineers

---

Владелец: Вадим Рудаков, lefthand67@gmail.com  
Версия: 0.1.0

---

Учебное пособие для начинающих инженеров, которое знакомит с ключевыми угрозами безопасности в области **Глубокого обучения** (Deep Learning, DL) и **Обработки естественного языка** (Natural Language Processing, NLP), с акцентом на **Большие языковые модели** (Large Language Models, LLMs) вроде GPT и аналогичных систем. Включены примеры из реальной практики и описание значимости каждой области угроз для мгновенного понимания контекста.

**Почему безопасность LLM имеет значение**

Современные большие языковые модели (LLMs) — это мощные инструменты, которые помогают бизнесу, организациям и отдельным пользователям автоматизировать процессы, создавать контент и взаимодействовать с пользователями. Однако вместе с этим они несут новые риски безопасности, которые часто плохо понимаются вне круга специалистов. По мере того как LLM находят применение в чувствительных сферах — юридической, медицинской, в службах поддержки клиентов и при разработке кода — важность понимания их уязвимостей растет с каждым годом.

| Архитектурный слой | Типичные угрозы и атаки                                          | Пример из практики                                                | Почему это важно                                           | Ключевые навыки и знания                                  | Рекомендации и меры защиты                                                    |
|--------------------|-------------------------------------------------------------------|-------------------------------------------------------------------|------------------------------------------------------------|-----------------------------------------------------------|--------------------------------------------------------------------------------|
| **1. Execution**   | Злонамеренное выполнение кода, повышение привилегий, побег из среды выполнения | Эксплойт плагина, исполняющий shell-команды на сервере вывода (inference server) | Компрометация позволяет атакующему взять под контроль хостинг | Безопасность контейнеров, песочница (sandboxing), защита среды выполнения   | Используйте песочницу, минимизируйте привилегии, проводите аудит расширений и плагинов |
| **2. Model**       | Ввод вредоносных команд (Prompt injection), джейлбрейк (jailbreaks), упразднение отказов (abliteration), извлечение модели (model extraction), отравление обучения, [обратное восстановление модели](https://hub.soviar.ru/brazas/culture/src/branch/develop/engineering/ai/2_model/security/model_inversion_attacks.md) | Пользователь формирует запрос для обхода отказов или извлечения конфиденциальных обучающих данных | Обход защитных механизмов ведет к токсичному выводу или утечке данных | Внутреннее устройство модели, тестирование на устойчивость (adversarial testing), безопасная донастройка (secure fine-tuning) | Ограничивайте доступ к API/ключам, мониторьте запросы, проводите аудит, защищайте веса |
| **3. Infrastructure**| Утечки данных, сетевые атаки, компрометация цепочки поставок (supply chain), ошибки конфигурации хранения | Открытые облачные хранилища (cloud buckets) раскрывают веса моделей или журналы | Даже надежные модели уязвимы при ошибках инфраструктуры | Безопасность облака, сегментация сети (network segmentation), шифрование | Шифруйте данные при хранении и передаче, проверяйте контроль доступа и зависимости |
| **4. Orcestration**  | Не безопасная передача между микросервисами, ошибки конфигурации потоков, внедрение между компонентами | Вредоносный запрос проходит через цепочку агентов, обходя проверки | Сложные рабочие процессы создают неожиданно новые векторы атак | Безопасность API, авторизация сервиса, проверка потоков (workflow validation) | Аутентифицируйте все вызовы между сервисами, проверяйте потоки данных, мониторьте аномалии |
| **5. Context**     | Отравление контекста (context poisoning), внедрение команд через извлеченные документы, утечка данных в контексте | Вредоносные документы в системе извлечения (retrieval-augmented generation) запускают джейлбрейк | Атакующие манипулируют контекстом, чтобы обойти фильтры и вызвать утечку данных | Инжиниринг запросов (prompt engineering), проверка ввода, очистка данных (data sanitization) | Проверяйте и очищайте все входы контекста, мониторьте ввод/вывод, ограничивайте источники извлечения |

**Как использовать эту таблицу**

- **Сфокусируйте обучение:** Определите свою роль (например, DevOps, ML-инженер, разработчик приложений) и отдавайте приоритет слоям, связанным с вашей работой.
- **Защита на всех уровнях (Defense in Depth):** Понимайте, что атакующие используют самые слабые слои; многоуровневая защита уменьшает системный риск.
- **Сотрудничайте:** Эффективная безопасность зависит от четкой коммуникации и согласованной защиты на всех архитектурных слоях.
