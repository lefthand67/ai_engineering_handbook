# Prompt as Infrastructure: Стандарты, хранение и автоматизация промптов в AI CI/CD

---

Владелец: Вадим Рудаков, lefthand67@gmail.com  
Версия: 0.3.0

---

Методологический гайд по инженерии промптов в реальных DevOps‑ и CI/CD‑окружениях.

Статья посвящена методам формализации и стандартизации промптов как ключевых разработческих артефактов.
- Рассмотрены принципы хранения промптов в структурированных форматах JSON и YAML с применением внутренней XML-подобной разметки для семантической организации. 
- Описаны подходы декларативного дизайна, семантического версионирования и автоматической проверки (валидации) с помощью схем и Pydantic. 
- Показана организация статических и динамических частей промптов для масштабируемого и безопасного использования в пайплайнах AI CI/CD с сопровождением юнит-тестами. 

Путаница вокруг Git-ориентированного инженерного проектирования промптов — использовать ли JSON, XML, Markdown или фреймворки вроде DSPy — распространена среди технических команд, запускающих продукты на базе ИИ в 2025 году. Лучшие практики сейчас сходятся к хранению структурированных, версионированных артефактов промптов в Git, но подход к реализации (вручную или программно, промпт-как-данные или промпт-как-код) зависит от масштаба, уровня компетенции команды и требований к будущей устойчивости.

---

## 1. Хранение и версионирование промптов

Все промпты, шаблоны и их метаданные должны храниться в структурированных форматах, где используется специальная разметка. Это означает, что вы не просто сохраняете текст в файлах или копируете встроенные промпты в код, а относитесь к ним как к полноценным конфигурационным артефактам.

Храните все промпты, шаблоны и параметры как конфигурационные/датасет-файлы с последовательно применяемой разметкой в Git. Это позволяет:
- отслеживать историю, 
- проводить ревью, 
- проводить ветвление для экспериментов и 
- проводить автоматизированное развертывание через CI/CD конвейеры.

Избегайте хранения промптов как свободного текста в коде, вики или обычных файлах. Ручное редактирование без версионирования ведет к «тихим» регрессиям и отсутствию возможности аудита или отката ошибок:

> Вы не сможете точно знать, какая версия промпта вызвала тот или иной системный результат. Это становится серьёзной проблемой, когда ваша система работает в продакшене и вам нужна воспроизводимость.

**Основные приницпы:**

- **Семантическое версионирование файлов с промптами**: например, `summarizer_v1.1.0.yaml`; каждое обновление промпта — отдельный файл/коммит.
- **Интеграция с CI/CD**: проверка валидности промптов (схемы, плейсхолдеры) и тесты с примерами входов/выходов на каждом `branch/PR`.
- **Автоматизированное развертывание**: используйте Ansible/Terraform или кастомные Python-скрипты для синхронизации валидированных промптов в продукционные inference endpoints, избегая ручного копипаста.
- **Откаты и аудит**: любая правка промпта отслеживаема (кто/когда/что/почему) через Git.

Итак,

> *промпт ≠ код, но это артефакт разработки, который тоже должен иметь стандарты.*

## 2. Разметка промпта

Git — это основа, но важен формат. 

Разметка промптов еще находится в стадии бурного развития, стандартов не существует. Тем не менее вендоры и специалисты выработали несколько зарекомендовавших себя подходов, ниже представлены самые известные из них.

> Внимание! Выбор синтаксиса разметки промптов менее важен, чем его последовательное применение в архитектуре системы. 

### 2.1 Подходы

| Методология | Описание | Плюсы | Минусы | Лучше всего подходит для |
| --- | --- | --- | --- | --- |
| **XML-подобные теги** (`<role>`, `<instruction>`, `</role>`) | Использует открывающие и закрывающие теги для определения секций. | - Высокий уровень структурированности.<br>- Легко парсить.<br>- Однозначность. | - Многословность увеличивает количество токенов.<br>- Может выглядеть неестественно в тексте промпта. | Сложные многошаговые цепочки рассуждений, где важна чёткая иерархия. |
| **Ad-hoc разделители** (например, `###`) | Используются повторяющиеся символы для выделения границ секций. | - Менее многословно, чем XML.<br>- Визуально выделяется для человека и парсера.<br>- Становится стандартом. | - Возможны конфликты с другой разметкой (например, Markdown).<br>- Требует согласования команды. | Общая структуризация промптов, в том числе в многоагентных системах, где выводы становятся входными данными. |
| **Заголовки на естественном языке** (`Role:`, `Instructions:`) | Использует обычный язык для обозначения секции. | - Наиболее удобно для человека.<br>- Нет конфликтов синтаксиса. | - Модель может легко проигнорировать или неверно интерпретировать.<br>- Трудно парсить программно. | Простые однократные промпты, где главное — удобство чтения человеком. |
| **Структурированные данные** (JSON, YAML) | Весь промпт представлен в виде структурированного объекта. | - Машиночитаемость по определению.<br>- Идеально для обмена между агентами.<br>- Гарантируется схема. | - Плохо читается и пишется человеком.<br>- Не все интерфейсы LLM с этим работают. | **Идеальный вариант для передачи данных между агентами вашей системы.** |

Таким образом, большое значение на то, какой синтаксис для разметки промптов выбрать, оказывает несколько факторов:
1. Цель использования - для чата или межагентного взаимодействия.
1. Особенности обучения данной конкретной модели - смотреть рекомендации вендоров.

### 2.2 Internal Agent Prompting vs Inter-Agent Communication

Необходимо разделять концепции *внутреннего промптинга агента* (*internal agent prompting*) и *межагентской коммуникации* (*inter-agent communication*).

#### Internal Agent Prompting: Стандартизация разделителей для ясности внутреннего промпта

Для внутренних инструкций *в рамках* промпта одного агента (system prompt) последовательно используйте паттерн `### SECTION ###`.

OpenAI [рекомендует](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api) использовать разделители, такие как `###`, для отделения инструкций от контекста. Конкретный шаблон `### SECTION ###` — это разработанное сообществом расширение этого принципа, которое обеспечивает ещё более чёткие семантические границы для сложных запросов. 

> Его основное преимущество — высокая видимость и маловероятность спутать с содержимым. Он создает чёткие визуальные и семантические границы для LLM, помогая отделять роль, пользовательский ввод, инструкции и формат вывода. Конфликт с Markdown не важен, так как промпт не отображается в Markdown, а является чистым текстом.
    
#### Межагентное взаимодействие: Применение строгого структурированного протокола данных для передачи между агентами

Для любого вывода одного агента, который станет вводом для другого, обязательно используйте строгую схему вывода в формате YAML/JSON. Это становится "контрактом" между агентами.

> В промпте агенту указывается: "*Ваш итоговый вывод ДОЛЖЕН быть валидным JSON-объектом согласно следующей схеме: {...}*". При этом разделители `###` используются *внутри самого промпта* для отделения секций инструкций для агента.

**Проблемы:**
	- Затраты на реализацию: высокие. Требуется тщательная разработка JSON-схем для каждого типа вывода агента.
	- Использование токенов: возможно, выше, но структура значительно снижает ошибки парсинга и галлюцинации.
	- Новые риски: агент может выдать невалидный JSON, поэтому нужен слой валидации в коде (например, модель Pydantic в Python) для проверки и повторного запуска.
	
Это фундаментальный паттерн многоагентных архитектур. Он обсуждается в ресурсах по **Agent Frameworks** вроде AutoGen и [CrewAI](https://docs.crewai.com/core-concepts/Tasks/).

**Такой подход обеспечивает:**

1. **Интеграцию с системой контроля версий (Git)**
   - Когда промпты хранятся в структурированных файлах, Git легко может сравнивать их и отслеживать изменения во времени.
   - Пример: если завтра вы измените “temperature” с 0.3 на 0.4, diff в Git покажет именно это — полезно для аудита и воспроизводимости.
2. **Машинная читаемость и автоматическая валидация**
   - Структурированные форматы позволяют писать валидаторы и линтеры (например, JSON Schema, pydantic или проверки наподобие OpenAPI).
   - Это предотвращает ошибки вроде отсутствующих плейсхолдеров (`{text}`), недопустимых значений параметров или несогласованных названий.
3. **Удобство генерации вариантов и тестовых наборов**
   - Поскольку промпты — это данные, вы можете программно генерировать варианты A/B/C (например, разные стили для суммаризации).
   - Также можно автоматически собирать наборы тестов-промптов для проверки того, что новые версии моделей ведут себя согласованно.

## 3. Декларативный подход и модульная архитектура

### Аннотация
Документ описывает архитектурные паттерны для построения устойчивых промпт-систем в корпоративной среде. Основное внимание уделяется **декларативному разделению** определения промптов (конфигурация) от логики их исполнения (код) и **модульной композиции** через систему строгих контрактов. Представленные методики обеспечивают соответствие стандартам ISO 29148, повторяемость результатов и эффективное управление версиями в multi-agent средах.

### Ключевые принципы
1. **Промпт-как-конфигурация**: Определения промптов хранятся как данные, а не код
2. **Контракты-первыми**: Схемы входов/выходов определяются до реализации логики
3. **Модульность через композицию**: Сложные промпты собираются из переиспользуемых компонентов
4. **Сквозная валидация**: Проверка на этапах сборки, тестирования и исполнения

### 3.1 Что vs Как

Следует разделять "*что*" (промпт и его параметры) от "*как*" (бизнес-логика, которая их использует и обрабатывает). Такой подход называется декларативным, так как ваши промпты не содержат вшитой в них бизнес-логики и являются по сути декларативными шаблонами - *что* нужно сделать. Детали конкретного бизнес-запроса генерируются из отдельно хранимых файлов в ходе компиляции или непосредственно на лету при исполнении промпта (отдельная тема для обсуждения).

**Пояснение**

- Декларативный дизайн ориентирован на описание *того, что* нужно получить, а не *как* это реализовать.
- В этом случае указывается текст промпта, плейсхолдеры и параметры (например, `max_tokens`, `temperature`) в виде простых структур данных (YAML или JSON).
- В противоположность этому — внедрение текста промпта и логики как кода, например, жестко прописанные строки промпта внутри функций, либо смешивание бизнес-логики с генерацией промптов.

> Таким образом, необходимо хранить определения промптов исключительно как данные или конфигурационные файлы без вшитых в них запросов от бизнеса.

**Преимущества декларативного подхода в промпт-инжиниринге**

1. **Переиспользуемость и согласованность**:
  - Одно определение промпта может быть загружено и использовано в разных компонентах — например, в пайплайнах обучения, скриптах валидации и inference-серверах. Это обеспечивает согласованное поведение.
2. **Разделение обязанностей**:
  - Бизнес-логика (потоки данных, принятие решений) остается отделенной от содержания промпта. Это упрощает поддержку и развитие обеих частей независимо друг от друга.
3. **Валидация и автоматизация**:
  - Поскольку промпт — это только данные, его можно автоматически проверять по схемам (обязательные поля, плейсхолдеры) и автоматизировать задачи наподобие подстановки плейсхолдеров без ручного парсинга.
4. **Проще совместная работа**:
  - Люди без навыков программирования (дизайнеры промптов, лингвисты) могут просматривать и редактировать конфиги промптов без необходимости разбираться в коде.
  
#### Пример

> Для промышленной системы требуется не просто декларативное описание, а строго типизированное. Подход с использованием JSON-схем (например, через Pydantic в Python) является де-факто стандартом для решения этой задачи.

Представьте, что у вас есть агент для генерации пользовательских историй (User Stories). Вместо того чтобы встраивать промпт в код, мы выносим его в отдельный конфигурационный файл.

**1. Декларативный шаблон промпта (`user_story_prompt.json`)**
Это «что» нужно сделать.

```json
{
  "name": "generate_user_story",
  "version": "0.1.0",
  "description": "Генерация пользовательской истории на основе роли и цели",
  "template": "Сгенерируй пользовательскую историю в формате ISO 29148 для проекта {project_name}.\nРоль: {user_role}\nЦель: {user_goal}\nКритерии приемки должны быть конкретными и тестируемыми.\nВыведи результат в формате JSON.",
  
  "output_schema": {
    "type": "object",
    "properties": {
      "user_story": {
        "type": "string"
      },
      "acceptance_criteria": {
        "type": "array",
        "items": {
          "type": "string"
        }
      }
    },
    "required": ["user_story", "acceptance_criteria"]
  },
  
  "parameters": [
    {
      "name": "project_name",
      "type": "string",
      "required": true,
      "description": "Название проекта"
    },
    {
      "name": "user_role", 
      "type": "string",
      "required": true,
      "description": "Роль пользователя"
    },
    {
      "name": "user_goal",
      "type": "string", 
      "required": true,
      "description": "Цель пользователя"
    }
  ],
  
  "metadata": {
    "created": "2024-01-15",
    "author": "ai-team",
    "tags": ["user_story", "requirements", "iso29148"]
  }
}
```

**2. Исполняющая бизнес-логика (Python-код с JSON)**
«Как» это используется.

```python
import json
from pydantic import BaseModel, ValidationError
from typing import List

# Модель данных для валидации выходных данных
class UserStoryOutput(BaseModel):
    user_story: str
    acceptance_criteria: List[str]

# Модель для валидации параметров
class PromptParameters(BaseModel):
    project_name: str
    user_role: str
    user_goal: str

# Функция загрузки и выполнения промпта
def load_and_execute_prompt(prompt_file_path: str, parameters: dict, llm_client):
    """
    Загружает JSON-шаблон промпта, валидирует параметры, 
    рендерит промпт и выполняет валидацию вывода LLM
    """
    # 1. Загружаем и валидируем конфиг промпта
    with open(prompt_file_path, 'r', encoding='utf-8') as file:
        prompt_config = json.load(file)
        
    # 2. Валидируем входные параметры
    try:
        validated_params = PromptParameters(**parameters)
    except ValidationError as e:
        raise ValueError(f"Parameter validation failed: {e}")
    
    # 3. Рендерим промпт, подставляя параметры
    rendered_prompt = prompt_config['template'].format(
        project_name=validated_params.project_name,
        user_role=validated_params.user_role, 
        user_goal=validated_params.user_goal
    )
    
    # 4. Добавляем инструкцию по формату вывода на основе output_schema
    output_instruction = "\n\nOutput must be valid JSON matching this schema: " + json.dumps(prompt_config['output_schema'], ensure_ascii=False)
    final_prompt = rendered_prompt + output_instruction
    
    # 5. Отправляем промпт в LLM
    llm_response = llm_client.generate(final_prompt)
    
    # 6. Парсим и валидируем выходные данные LLM
    try:
        parsed_output = json.loads(llm_response)
        validated_output = UserStoryOutput(**parsed_output)
        return validated_output
    except (json.JSONDecodeError, ValidationError) as e:
        raise ValueError(f"LLM output validation failed: {e}")

# Пример использования
parameters = {
    "project_name": "Система управления складом",
    "user_role": "Кладовщик", 
    "user_goal": "Отметить прибытие новой партии товара на склад"
}

# Вызов функции
try:
    result = load_and_execute_prompt("user_story_prompt.json", parameters, my_llm_client)
    print("Сгенерированная пользовательская история:")
    print(result.user_story)
    print("\nКритерии приемки:")
    for i, criterion in enumerate(result.acceptance_criteria, 1):
        print(f"{i}. {criterion}")
except ValueError as e:
    print(f"Ошибка: {e}")
```

**3. Пример ожидаемого вывода LLM**

```json
{
  "user_story": "Как кладовщик, я хочу отметить прибытие новой партии товара на склад, чтобы система обновила учетные данные и обеспечила точность инвентаризации.",
  "acceptance_criteria": [
    "Система должна подтвердить успешное добавление партии товара в базу данных",
    "Должна быть создана соответствующая запись в журнале поступлений",
    "Количество товара на складе должно автоматически увеличиться на величину прибывшей партии",
    "Система должна уведомить ответственных лиц о завершении операции"
  ]
}
```

### 3.2 Внутренний и внешний слои промпта

**Внутренний слой** промпта состоит из следующих частей:
- системный промпт,
- пользовательский промпт,
- любые дополнительные пользовательские данные, контекст и т.п.,

т.е. все то, что мы обычно называем "промптом".

Для внутреннего слоя можно использовать любую рассмотренную выше разметку, которая оправдывает себя на данной модели для данной задачи, то есть вырабатывается экспериментально.

**Внешний слой** - это контейнер промпта, который объединяет:
- внутренний слой и
- метаданные данной сборки (версии промпта).

Для CI/CD внешний слой промпта рекомендуется вести в JSON формате, однако можно использовать и другие структурированные форматы, если у вас есть для них подходящий парсер.

#### Пример многоуровневой композиции промптов - разделения хранения промптов и внутренней разметки
  
- Промпты **хранятся** как структурированные данные в JSON (или YAML).
- **Внутри** программного поля `template` находится текст промпта с XML-подобной семантической разметкой для точного структурирования контента, понятного данной модели.

**1. Внешний уровень (JSON-контейнер)**
```json
{
  "id": "business_analyst_agent_v1",
  "version": "1.2.0",
  "description": "Агент анализа бизнес-требований",
  "template_placeholder": "{assembled_prompt}",
  "components": [
    "system_role_ba",
    "business_context_module",
    "requirement_framework_iso29148",
    "output_format_json"
  ],
  "parameters": {
    "temperature": 0.1,
    "max_tokens": 2000
  },
  "metadata": {
    "created": "2024-01-15",
    "author": "ai-team",
    "tags": ["business-analysis", "iso29148", "enterprise"]
  }
}
```

**2. Внутренний уровень (Модульные блоки промпта)**

`"{assembled_prompt}"` - это и есть внутренний слой, который необходимо подготовить отдельно.

- Файл: `prompt_components/system_role_ba.json`
```json
{
  "type": "system",
  "content": "Вы — старший бизнес-аналитик с 15-летним опытом в корпоративном ПО. Специализация — инженерия требований по ISO 29148.",
  "priority": 1
}
```

- Файл: `prompt_components/business_context_module.json`
```json
{
  "type": "context",
  "content": "Проект: {project_name}\nДомен: {domain}\nЗаинтересованные стороны: {stakeholders}",
  "priority": 2
}
```

- Файл: `prompt_components/requirement_framework.json`
```json
{
  "type": "methodology",
  "content": "Применяйте стандарт ISO 29148. Требования должны быть: однозначными, проверяемыми, отслеживаемыми, последовательными.",
  "priority": 3
}
```

**3. Движок сборки**

```python
class PromptAssembler:
    def __init__(self, components_dir: str):
        self.components_dir = components_dir

    def assemble_prompt(self, template_config: dict, dynamic_params: dict) -> str:
        """Сборка итогового промпта из модульных компонентов"""
        components = []

        # Загрузка компонентов в порядке приоритета
        for component_id in template_config['components']:
            component_path = f"{self.components_dir}/{component_id}.json"
            with open(component_path, 'r') as f:
                component = json.load(f)
            
            # Рендеринг с динамическими параметрами
            rendered_component = component['content'].format(**dynamic_params)
            components.append(rendered_component)
        
        # Объединение с разделителями
        final_prompt = "\n\n".join(components)
        return final_prompt

# Пример использования
assembler = PromptAssembler("prompt_components")
template_config = load_template("business_analyst_agent_v1.json")
dynamic_params = {
    "project_name": "Warehouse Management System",
    "domain": "Логистика",
    "stakeholders": "Сотрудники склада, IT-отдел, руководство"
}

final_prompt = assembler.assemble_prompt(template_config, dynamic_params)
```

Данная схема используется в:
- **Semantic Kernel от Microsoft** (Plugins + Functions)
- **LangChain** (PromptTemplate + FewShotPromptTemplate)
- **Amazon Bedrock** (Управление промптами из компонентов)

### 3.3 Валидация схемы внешнего слоя промпта

> Требуется проработка и валидация информации

Определите JSON Schema (или Pydantic-модель в Python), чтобы автоматически проверять корректность файлов с промптами. Пример:

```json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "required": ["id", "description", "template", "parameters"],
  "properties": {
    "id": { "type": "string" },
    "description": { "type": "string" },
    "template": { "type": "string" },
    "parameters": {
      "type": "object",
      "properties": {
        "max_tokens": { "type": "integer", "minimum": 1 },
        "temperature": { "type": "number", "minimum": 0, "maximum": 1 }
      },
      "required": ["max_tokens", "temperature"]
    },
    "author": { "type": "string" },
    "created_at": { "type": "string", "format": "date-time" },
    "last_modified": { "type": "string", "format": "date-time" }
  }
}
```

Эта схема позволяет выявить проблемы вроде отсутствующих плейсхолдеров, некорректных диапазонов параметров или пропусков в метаданных ещё на этапе CI/CD перед развёртыванием промптов.

#### Pydantic модель

Pydantic — это популярная библиотека в Python для валидации данных и управления настройками. Она позволяет описывать ожидаемую структуру данных и автоматически проверять и парсить вход в соответствии с моделью.

- Pydantic-модели позволяют **декларировать ожидаемую структуру данных с типами прямо в Python**.
- Они **автоматически валидируют и парсят** данные, чтобы убедиться в их корректности.
- Идеальны для **валидации схемы файлов промптов**, конфигураций или любого структурированного ввода.

**Что такое Pydantic модель?**

- Pydantic-модель — это класс Python, унаследованный от `pydantic.BaseModel`.
- Внутри объявляются поля с типами, отражающие структуру данных.
- При создании экземпляра модели с входными данными Pydantic:
  - Проверяет соответствие типов и ограничений.
  - Автоматически преобразует типы, если возможно (например, строки в даты).
  - Вызывает понятные ошибки при несоблюдении схемы.
- Это позволяет принудительно выполнять валидацию схемы программно в Python.

**Почему использовать Pydantic для файлов промптов?**

- Мы можем валидировать определения промптов (JSON/YAML) до загрузки в пайплайн.
- Исключается отсутствие полей, ошибки в типах или неправильные диапазоны.
- Полезные сообщения об ошибках фиксируются на этапе тестов или CI.
- Повышается надёжность и поддерживаемость кода.

**Простой пример Pydantic-модели:**

```python
from pydantic import BaseModel, Field
from typing import Dict

class PromptModel(BaseModel):
    id: str
    description: str
    template: str
    parameters: Dict[str, float] = Field(default_factory=dict)
    author: str = None
    created_at: str = None
    last_modified: str = None

# Example usage
data = {
    "id": "summarizer_v1",
    "description": "Prompt for text summarization",
    "template": "<instruction>Summarize:</instruction>\n<content>{text}</content>",
    "parameters": {"max_tokens": 512, "temperature": 0.3},
    "author": "Jane Doe",
    "created_at": "2025-08-01T12:00:00Z"
}

prompt = PromptModel(**data)  # Validates input here

print(prompt.id)  # Access fields normally
```

Если входные данные не соответствуют схеме (например, отсутствует `id` или тип неверный), Pydantic мгновенно выдаст ошибку.

#### Юнит-тесты промптов

Пример теста (Python-псевдокод):

```python
def test_summarizer_prompt_format():
    prompt = load_prompt("summarizer_v1.json")
    input_text = "OpenAI is an AI research lab."
    full_prompt = prompt["template"].format(text=input_text)
    
    # Assert placeholder substitution
    assert "{text}" not in full_prompt
    
    # Assert key elements present
    assert "Summarize the following text:" in full_prompt
    assert input_text in full_prompt

    # Optionally, call mock model and verify output format
    mock_output = mock_model_response(full_prompt)
    assert isinstance(mock_output, str) and len(mock_output) > 0
```

Такие тесты помогают убедиться, что изменения промптов не ломают форматирование или поведение, предотвращая регрессии в продакшене.

## 4. Внутренний слой промпта: Статические (system) vs динамические (user) части промпта

### 4.1 Шаблон System-User Pattern

Фундаментальный принцип архитектуры промпт-систем, известный как **шаблон "Система-Пользователь" (System-User Pattern)** или разделение на "статический контекст" и "динамический контекст". 

- Часть **system** один раз определяет роль ассистента и правила.  
- Часть **user** подключается во время выполнения с фактическим переменным вводом (`{text}`).

Это широко используемый шаблон в API ИИ-чатов, таких как чат-запросы OpenAI, где передаются отдельные сообщения `system` и `user`, отражающие соответственно статические и динамические части промпта.

> Обратите внимание на **программные оболочки для LLM** (например, **LangChain**, **LlamaIndex**), которые формализуют это разделение через концепции `SystemMessage`, `HumanMessage`, `Templates` и `Tools`. Это следующий шаг эволюции от ручного управления промптами к управлению через код.

Пример YAML:

```yaml
system_prompt:
  id: system_instructions_v1
  content: |
    You are a helpful assistant. Always respond politely and concisely.
    Follow JSON format in output.
```

```yaml
user_prompt:
  id: user_prompt_v1
  template: |
    Summarize the following text:
    {{ text }}
```

где `{{ text }}` также является внешним блоком, который подставляется в данный пользовательский промпт.

### 4.2 Какие проблемы закрывает

Проблема, которую решает данный принцип, это обеспечение **согласованности, управляемости и эффективности** в мультиагентной системе.

> System-User Pattern - это стандарт де-факто для построения надежных агентов.

Приницп призван решить ключевую проблему проектирования промптов: **смешение инструкций и данных**. Без такого разделения происходит:
1.  **Контекстное загрязнение:** Критически важные системные инструкции "размываются" в море пользовательских данных, что приводит к их игнорированию моделью.
2.  **Отсутствие версионности:** Изменение бизнес-логики (системный промпт) невозможно отследить отдельно от изменения входных данных (пользовательский промпт).
3.  **Низкая эффективность:** Постоянная переотправка одних и тех же статических инструкций раздувает токенный бюджет и затраты.
4. **Сложная поддержка промптов:** Написание нового промпта требует ручного копирования и вставки частей уже зарекомендовавших себя промптов вместо их динамического использования в лучших программистских практиках DRY - Don't Repeat Yourself.

### 4.3 Сравнение с другими подходами

Подход является конкретной реализацией более широких методологий проектирования интерфейсов "человек-ИИ" и "ИИ-ИИ". Сравним его с альтернативами.

| Методология | Описание | Плюсы | Минусы | Лучше всего подходит для | Источник |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Система-Пользователь** | Жесткое разделение на статические (роль, правила, формат) и динамические (данные, запрос) компоненты промпта. | **Высокая согласованность,** упрощенное версионирование, эффективное использование контекста. | Требует дисциплины проектирования; может быть избыточным для простых, разовых задач. | **Промышленные, multi-agent системы,** требующие повторяемости и контроля. | [OpenAI Cookbook - Techniques to Improve Reliability](https://cookbook.openai.com/articles/techniques_to_improve_reliability) |
| **Монолитный промпт** | Все инструкции и данные передаются в одном сообщении пользователя. | Простота для быстрого прототипирования. | Нестабильность, сложность управления, непредсказуемость при изменении входных данных. | Быстрое тестирование идей, одиночные запросы. | Это общераспространенная, но не рекомендуемая практика. |
| **Цепочка мысли (Chain-of-Thought)** | Пошаговое рассуждение, встроенное в промпт или запрашиваемое у модели. | Увеличивает точность для сложных логических задач. | Увеличивает объем вывода и сложность промпта; не решает проблему разделения кода и данных. | Задачи, требующие логических рассуждений и математических вычислений. | [Chain-of-Thought Prompting](https://arxiv.org/abs/2201.11903) |

### 4.4 Стратегии для реализации System-User Pattern

| Стратегия | Описание | Компромисс | Источник |
|--------|----------|------------|----------|
| **Строгий контракт на выходные данные (Strict Output Schema)** | В системном промпте явным образом определите формат вывода (например, JSON с конкретными полями). Это превращает выход агента в структурированные данные, которые легко потребляются следующим агентом. | Требует более сложной обработки ошибок (например, если модель выдает невалидный JSON), но кардинально повышает надежность меж-агентного взаимодействия. | [OpenAI Platform - Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs) |
| **Многоуровневая валидация (Multi-Stage Validation)** | Создайте отдельного "агента-валидатора". Его системный промпт статически определяет критерии качества (например, "критерий приемки должен быть конкретным и тестируемым"), а пользовательский промпт — передает на проверку выход основного агента. | Значительное увеличение вычислительных затрат (токены, вызовы API), но это страховка от пропуска ошибок в продакшене. | Это сгенерированный подход, основанный на принципах software testing. |
| **Промпт-как-код (Prompt-as-Code)** | Храните системные промпты в отдельных файлах (например, `business_analyst_system_prompt.v1.j2`). Используйте шаблонизатор (Jinja2) для инъекции динамических переменных из пользовательского промпта. Это реализует версионность и контроль. | Усложняет инфраструктуру, но дает полный контроль и соответствие DevOps-практикам. | Это сгенерированный подход, основанный на инженерных практиках. |

**Какую стратегию выбрать?**

| Параметр сравнения | Строгий контракт на выходные данные | Многоуровневая валидация | Промпт в виде кода |
|--------------------|-----------------------------------|--------------------------|-------------------|
| **Основная цель** | Стандартизация формата вывода между агентами | Обеспечение качества и соответствия стандартам | Управление версиями и инфраструктурой |
| **Уровень применения** | Уровень отдельного агента | Уровень системы (меж-агентное взаимодействие) | Уровень инфраструктуры |
| **Сложность реализации** | 🔧 Средняя | 🔧🔧🔧 Высокая | 🔧🔧 Средняя |
| **Токенные затраты** | +0-10% (дополнительные инструкции) | +100-200% (дополнительный агент) | +0% (инфраструктурные) |
| **Влияние на надежность** | 🟢 Высокое (структуризация вывода) | 🟢🟢 Очень высокое (двойной контроль) | 🟢 Среднее (снижение человеческих ошибок) |
| **Требуемые навыки** | JSON-схемы, валидация данных | Тестирование, критерии качества | DevOps, шаблонизация, системы контроля версий |
| **Интеграция с CI/CD** | Частичная (тесты структуры) | Полная (валидация как этап пайплайна) | Полная (инфраструктура как код) |
| **Гибкость** | Средняя (жесткая схема) | Высокая (настраиваемые критерии) | Очень высокая (модульность) |
| **Время внедрения** | 1-2 дня на агента | 3-5 дней на систему | 2-4 недели на инфраструктуру |
| **Технический долг** | Низкий (ясная схема) | Средний (поддержка валидаторов) | Средний (обслуживание шаблонов) |

#### Оптимальная комбинация для enterprise-проектов

```python
# Уровень 1: Промпт как код (инфраструктура)
prompt_template = """
# {{agent_role}}
# Версия: {{version}}
# Стандарты: {{standards}}

{{base_instructions}}

# Формат вывода (строгий контракт):
{{output_schema}}
"""

# Уровень 2: Строгий контракт (агент)
output_schema = {
    "type": "object",
    "properties": {
        "requirements": {"type": "array", "items": {"type": "string"}},
        "validation_status": {"type": "string", "enum": ["valid", "needs_review"]}
    }
}

# Уровень 3: Многоуровневая валидация (система)
validation_criteria = {
    "completeness": "Все требования должны быть конкретными",
    "testability": "Критерии должны быть проверяемыми",
    "traceability": "Связь с бизнес-целями"
}
```

### 4.5 Пример продвинутого шаблона (YAML)

```yaml
---
system:
    id: {{id}}
    version: {{version}}
    description: {{description}}
    metadata:
      author: {{author}}
      created_at: {{created_at}}
      domain: {{domain_description}}
      tech_stack: {{tech_stack_list}}
      last_validated: {{validation_date}}
      validation_notes: {{validation_notes}}

  # Core prompt components
  prompt_components:
    role:
      description: "AI persona definition and expertise domain"
      content: {{role_content}}

    context:
      description: "How to handle provided background information"
      content: {{context_handling_instructions}}

    process:
      description: "Step-by-step reasoning approach"
      content: {{step_by_step_process}}

    constraints:
      description: "Limitations and boundaries for responses"
      content: {{constraints_list}}

    examples:
      description: "Input-output pairs demonstrating desired behavior"
      content: {{few_shot_examples}}

    output_format:
      description: "Required structure and format for responses"
      content: {{format_specification}}

  # Inference parameters
  inference_parameters:
    temperature: {{temperature_setting}}
    max_tokens: {{max_output_length}}
    stop_sequences: {{stop_sequences}}

  # Validation framework
  validation:
    test_cases: {{test_case_references}}
    evaluation_metrics: {{metric_definitions}}
    compliance_requirements: {{compliance_rules}}
```

- `validation notes` — Эта строка является кратким подтверждением качества промпта, его надёжности и тех доменов, где он доказал свою эффективность. Это лучший практический элемент метаданных, который следует включать в любой серьёзный системный промпт промышленного уровня. **Проще говоря**, это означает: создатели этого системного промпта не просто предположили, что он будет работать. Они тщательно протестировали его на реалистичных примерах из двух разных доменов (e-commerce и AI agents), чтобы убедиться, что он выдаёт качественные и надёжные результаты, прежде чем признать его готовым к использованию.  

- `stop_sequences` — Это специальная инструкция для модели LLM, указывающая, когда она должна прекратить генерацию текста. Когда модель во время генерации встречает одну из этих последовательностей, она немедленно останавливается и не продолжает дальше. Цель состоит в том, чтобы дать ИИ чёткий и однозначный сигнал, что задание завершено, и он не должен продолжать.

## 5. Промышленные инструменты реализации принципа System-User Pattern

Проблема выбора инструментария для многоагентной системы — это компромисс между скоростью разработки, контролем над системой, масштабируемостью и наблюдаемостью. Не существует универсального решения; выбор зависит от фазы проекта и требуемого уровня абстракции.

### 5.1 Платформа vs Фреймворк

Следует провести фундаментальное разделение инструментов на две категории:
1.  **Платформы высшего уровня** (Maxim AI, PromptLayer): абстрагируют инжиниринг в визуальные интерфейсы, обеспечивая скорость и управление, но снижая глубину контроля.
2.  **Фреймворки/библиотеки** (DSPy, LangChain): предоставляют строительные блоки на коде, обеспечивая полный контроль и гибкость, но требуя значительных усилий по разработке и поддержке.

**Методологии выбора инструментария**

Следующая таблица систематизирует подход к выбору на основе ваших целей.

| Методология | Описание | Плюсы | Минусы | Лучше всего подходит для | Источник |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Platform-First (Сначала платформа)** | Начать с платформы (Maxim AI, PromptLayer) для быстрого прототипирования и валидации идей. | Быстрый старт, встроенные лучшие практики (A/B-тесты, версионирование). | Vendor lock-in, ограничения кастомизации, стоимость. | Команд, ориентированных на бизнес-результат, а не техническую реализацию. | Аналитика Gartner по платформам AI-разработки |
| **Framework-First (Сначала фреймворк)** | Начать с фреймворка (DSPy, LangChain) для построения системы с нуля под полным контролем. | Максимальная гибкость, прозрачность, избегание зависимости от вендора. | Высокие затраты на разработку, необходимость создавать инфраструктуру с нуля. | Исследователей и команд, где понимание "под капотом" критически важно. | Сообщества OpenAI и Hugging Face |
| **Hybrid (Комбинированный)** | Использовать фреймворк для ядра логики агентов, а платформу — для оркестрации, мониторинга и развертывания. | Баланс между контролем и скоростью разработки операционных задач. | Сложность интеграции, поддержка двух разных технологических стеков. | Промышленных проектов, где важны и контроль над логикой, и надежность эксплуатации. | Паттерн "Build vs. Buy" в корпоративной разработке |

**Рекомендуемый подход**
Для вашей цели — создания не "черного ящика", а настраиваемой системы — **Framework-First подход с элементами Hybrid является наиболее оправданным**. Ваша потребность в "глубоком понимании происходящего под капотом" исключает чистый Platform-First подход.

### 5.2 Framework-first

Коренная проблема — отсутствие единого, универсального "фреймворка" для реализации данного принципа в промышленной эксплуатации систем. Требуется комбинация:
1.  **Четких принципов проектирования** для разделения контекстов.
2.  **Инструментов и платформ**, поддерживающих шаблонизацию, версионирование и оркестрацию промптов.
3.  **Методологий разработки**, обеспечивающих согласованность и тестируемость.

**Методологии и подходы**

Следующая таблица сравнивает подходы к систематизации промпт-инжиниринга, которые формализуют принцип "Система-Пользователь".

| Методология / Подход | Описание | Плюсы | Минусы | Лучше всего подходит для | Источник |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **PromptChainer / LangChain (Chains)** | Концепция цепочек (chains), где выход одного промпта является входом для другого. Промпты шаблонизируются, разделяя статическую инструкцию и динамические переменные. | Высокая гибкость, прозрачность потока данных, легкость отладки. | Требует глубоких знаний программирования; "сырость" фреймворка LangChain может привести к техническому долгу. | Быстрого прототипирования сложных, многоэтапных конвейеров. | [LangChain Documentation](https://python.langchain.com/docs/modules/chains/) |
| **Microsoft's Prompt Flow** | Инструмент от Microsoft, визуально представляющий потоки промптов как графы с узлами (промпты, LLM, код) и связями. Прямо поддерживает шаблоны промптов. | Визуальный дизайнер, встроенное логирование, тестирование и мониторинг, интеграция с Azure AI. | Привязка к экосистеме Microsoft; менее гибкий для нестандартных задач по сравнению с кодом. | Промышленной разработки и развертывания надежных LLM-приложений в Azure. | [Prompt Flow Documentation](https://microsoft.github.io/promptflow/) |
| **CRISPE / DSPy** | **CRISPE** (Capacity, Role, Insight, Statement, Personality, Experiment) — это мета-фреймворк для структурирования статической части промпта. **DSPy** идет дальше, абстрагируя промпты в параметризуемые модули, которые оптимизируются автоматически. | DSPy автоматически генерирует эффективные промпты, снижая ручной труд; CRISPE обеспечивает отличную структуру. | Высокий порог входа; концептуально сложный; требует переобучения мышления. | Исследовательских задач и построения максимально оптимизированных систем, где ручная настройка промптов неэффективна. | [DSPy GitHub](https://github.com/stanfordnlp/dspy) |
| **ARM (Abstract Reasoning Model) / CAMEL** | Фреймворки для создания агентов с четкими ролями (системный контекст) и протоколами взаимодействия между ними (пользовательские сообщения). | Позволяет строить сложные многоагентные системы с контролируемым диалогом. | Чрезмерная сложность для большинства прикладных задач генерации требований. | Академических исследований и создания автономных агентных систем. | [CAMEL GitHub](https://github.com/camel-ai/camel) |

**Рекомендуемый подход**
Для вашей цели — создания промышленной системы для инжиниринга требований — наиболее оправдан комбинированный подход:
1.  **Ядро на Prompt Flow или аккуратном LangChain:** Эти инструменты предоставляют необходимую структуру для разделения статики и динамики, версионирования и оркестрации. Prompt Flow предпочтительнее для production-среды из-за встроенных инструментов мониторинга.
2.  **Использование принципов CRISPE:** При проектировании каждого промпта-агента (бизнес-аналитик, архитектор) используйте CRISPE как чеклист для заполнения статической (`system`) части. Это обеспечит полноту и стандартизацию.

### 5.3 Практические стратегии

**Практические стратегии**

1.  **Стратегия: DSPy как ядро системы агентов**
    *   **Шаблон:** Используйте DSPy для декларативного описания модулей ваших агентов (аналитик, архитектор). DSPy автоматически оптимизирует промпты (статическую часть `system`) под ваши метрики качества (однозначность, соответствие стандарту).
    *   **Компромисс:** Кардинально снижает ручной труд по настройке промптов и обеспечивает повторяемость. Высокий порог входа; вы должны будете глубоко изучить его парадигму (signatures, predictors, оптимизаторы).
    *   **Источник:** [DSPy GitHub Repository](https://github.com/stanfordnlp/dspy) и статья ["DSPy: Programming—not Prompting—Language Models"](https://arxiv.org/abs/2310.03714).

2.  **Стратегия: LangChain + Helicone для наблюдаемости и контроля**
    *   **Шаблон:** Постройте конвейер на LangChain (LCEL), определяя каждый агент как цепочку. Интегрируйте Helicone для логирования, отслеживания затрат и метрик производительности каждого вызова LLM.
    *   **Компромисс:** Дает полный контроль над потоком данных и отличную наблюдаемость. LangChain может быть избыточен для простых цепочек и добавляет абстракцию, которую некоторые считают ненужной.
    *   **Источник:** [LangChain Documentation](https://python.langchain.com/docs/expression_language/), [Helicone Documentation](https://docs.helicone.ai/).

3.  **Стратегия: PromptLayer для финальной стабилизации и коллаборации**
    *   **Шаблон:** После того как промпты агентов стабилизируются в DSPy/LangChain, зарегистрируйте их финальные версии в PromptLayer. Используйте его для A/B-тестирования небольших изменений и предоставления доступа нетехническим экспертам (например, бизнес-аналитикам) для ревью через визуальный интерфейс.
    *   **Компромисс:** Улучшает процессы коллаборации и управления промптами. Добавляет еще один инструмент в стек и может создать рассинхрон между кодом и платформой, если не настроен CI/CD.
    *   **Источник:** [PromptLayer Features](https://docs.promptlayer.com/features/overview).

**Возможные подводные камни и технический долг**
*   **Сложность DSPy:** Риск неправильного применения абстракций DSPy, что приведет к неоптимальным результатам и сложностям с отладкой. Требует инвестиций в обучение.
*   **Переусложнение с LangChain:** Для относительно линейного конвейера (агент 1 -> агент 2 -> отчет) чистое решение на Python с HTTP-клиентом может быть проще и надежнее.
*   **Фрагментация стека:** Использование нескольких инструментов (DSPy + LangChain + PromptLayer) создает операционные сложности и точки отказа.
*   **Хрупкость JSON-парсинга:** LLM может вывести невалидный JSON. Необходимо реализовать автоматические попытки перезапроса и валидацию.
*   **Дрейф контекста:** При изменении промпта одного агента могут возникнуть непредвиденные последствия для следующих агентов. Обязательно ведите семантическое версионирование промптов.
*   **Накопление статики:** Со временем `system`-промпты могут разрастаться. Требуется регулярный рефакторинг и удаление неиспользуемых инструкций для экономии токенов.

### 5.4 Точки роста

**Будущие тренды для наблюдения**
*   **Конвергенция:** Платформы будут добавлять возможности для low-code кастомизации логики агентов, а фреймворки — развивать инструменты мониторинга и управления (как Helicone для LangChain).
*   **Стандартизация интерфейсов:** Появление стандартов типа OpenLLM упростит интеграцию агентов, созданных на разных фреймворках, в единые платформы оркестрации.
*   **DSPy и аналоги:** Наблюдайте за развитием этих фреймворков. Когда они созреют, они могут кардинально упростить настройку промпт-систем.
*   **"Промпт-компиляторы":** Появление инструментов, которые транслируют высокоуровневые описания задач в оптимизированные цепочки промптов.

### 5.5 Список литературы для дальнейшего изучения

1.  **DSPy Official GitHub & Paper:** [Repository](https://github.com/stanfordnlp/dspy), [arXiv Paper](https://arxiv.org/abs/2310.03714) — фундаментальный источник для понимания парадигмы.
1.  **LangChain Documentation:** [Prompt Templates](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/) — пример реализации "промпта как кода" в популярном фреймворке.
1.  **LangChain vs. Custom Pipelines:** [Blog Post "You Might Not Need LangChain"](https://minimaxir.com/2023/07/you-might-not-need-langchain/) — важная статья, уравновешивающая энтузиазм к фреймворкам.
1.  **The Prompting Guide - Advanced Topics:** [Website](https://www.promptingguide.ai/) — содержит актуальные разделы по DSPy и другим передовым методам.
1.  **Helicone Blog:** [Blog](https://www.helicone.ai/blog) — кейсы внедрения мониторинга в LLM-пайплайны.
1.  **Microsoft DevBlog - Prompt Engineering:** [Patterns and Best Practices](https://devblogs.microsoft.com/sustainable-software/patterns-and-best-practices-for-prompt-engineering-with-llms/) — практические шаблоны, включая System-User.
