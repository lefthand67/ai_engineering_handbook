# Снижение галлюцинаций LLM: разбивайте задачи

---

Владелец: Вадим Рудаков, lefthand67@gmail.com  
Версия: 0.1.0  
Дата создания: 06.10.2025  
Дата изменения: 18.10.2025  

---

Подробный учебный материал для инженеров о сложности промптов LLM, ролях промптов и лучших практиках снижения галлюцинаций, основанный на методологии и примерах из реального мира.  

## Почему важен дизайн промптов

Современные большие языковые модели (LLM) — мощные инструменты, способные генерировать код, документацию и бизнес-логику в промышленном масштабе. Но их надёжность и качество вывода напрямую зависят от того, как формулируются задачи. Плохо спроектированные промпты — особенно те, что смешивают темы или лишены структуры — резко повышают риск галлюцинаций: модель выдает убедительно звучащий, но неверный или нелогичный результат. Понимание разницы между системным (system prompt) и пользовательским промптом (user prompt), а также умение проектировать промпты — это ключевые навыки для любого серьёзного специалиста в области ИИ.

## Методология: теоретический фундамент

### Системный промпт vs. Пользовательский промпт

- **Системный промпт**: задаёт постоянный контекст, личность и общие правила поведения модели в рамках сессии или развёртывания. Это защитный контур: например, «*Ты — полезный и ориентированный на безопасность ассистент» или «Не давай медицинских советов*».
- **Пользовательский промпт**: содержит непосредственную задачу. Каждый такой промпт указывает модели, что делать для конкретного запроса (например, «*Напиши Python-скрипт, совместимый с GDPR*» или «*Суммируй эту медицинскую статью*»).

**Ключевая идея:** ошибки в сложности пользовательского промпта — особенно смешение ролей или несвязанных тем — являются главной причиной галлюцинаций и сбоев модели. 

> **Системные промпты не могут исправить двусмысленные или перегруженные задачи.**

### Сложность задачи и галлюцинации

LLM хорошо справляются с «монотематическими» промптами-фильтрами, напоминающими SQL-запросы с `WHERE`-условиями:

```
SELECT data 
  FROM domain 
  WHERE condition
```

«Выбери данные из [контекст], где [условие]»

Добавление бизнес-ограничений или семантических фильтров упрощает внутренний поиск: модель выступает как комбинаторный извлекатель, сопоставляя паттерны и уточняя вывод по критериям.

Галлюцинации стремительно растут, если промпт превращается в «семантический JOIN», требуя свободного объединения разнородных областей (например, юридический анализ + рассказ + программирование в одном запросе).

**Пример SQL-запроса — аналог «галлюцинации»**

Хороший способ объяснить «семантический JOIN» — показать это на SQL, где избыточное объединение разных таблиц без чётких связей резко повышает риск «шума» и противоречий в результатах. 

```sql
SELECT l.law_text,          -- юридический анализ
       s.story_paragraph,   -- абзац художественного рассказа
       c.code_snippet       -- пример кода    
FROM legal_docs l
JOIN short_stories s ON l.id = s.id   -- совпадения между юр. документами и художественными рассказами не имеют смысла
JOIN code_examples c ON s.id = c.id   -- связь между рассказами и программным кодом тоже выдумана
WHERE l.topic LIKE '%GDPR%'
      AND s.theme LIKE '%юмор%'
      AND c.language = 'Python';
```

**Объяснение:**

- Здесь объединяются три совершенно разные сущности: 
    - законы (legal_docs), 
    - рассказы (short_stories) и 
    - код (code_examples).
- `JOIN`-условия искусственные и не отражают реальных связей.
- В результате получится «галлюцинирующий» результат: данные будут формально корректны для SQL, но по сути — бессмысленное смешение юриспруденции, литературы и программирования.

**Правильный подход (монотематический запрос)**

Чтобы избежать «семантического `JOIN`» в LLM-промптах, задачи надо разделять на отдельные вызовы (как и SQL-запросы):

```sql
-- Получить требования GDPR
SELECT law_text 
FROM legal_docs 
WHERE topic LIKE '%GDPR%';

-- Получить примеры кода по логированию
SELECT code_snippet 
FROM code_examples 
WHERE language = 'Python';

-- Получить художественный пример
SELECT story_paragraph 
FROM short_stories 
WHERE theme LIKE '%юмор%';
```

Так мы получаем три отдельных предсказуемых результата, которые можно потом объединить уже на уровне оркестровки, а не в одном «галлюцинирующем» запросе.

## Лучшие практики в проектировании промптов

**Пользовательские промпты**

- Будьте атомарными и монотематическими: разделяйте сложные бизнес-задачи на отдельные, ясно очерченные подзадачи — одна тема на промпт, одна роль на шаг генерации.
- Стройте пошаговые фильтры: используйте последовательные инструкции или композицию фильтров, чтобы модель работала в знакомых, богатых контекстом архетипах.
- Указывайте формат вывода: всегда уточняйте длину, тональность, тип данных (текст, JSON, таблица), ограничения результата. Это снижает неопределённость и помогает последующей автоматизации.
- Используйте примеры и цепочку рассуждений: для сложных задач давайте прямые примеры и просите модель «думать шаг за шагом» — это повышает стабильность вывода.
- Избегайте семантических помех: не смешивайте в одном промпте несколько целей (например, анализ + юмор + аудит). Разбивайте и организуйте их внешне.

**Системные промпты**

- Контекст, а не предписание: устанавливайте общий тон, ограничения и «личность» модели, но делегируйте детализацию задач пользовательским промптам.
- Поддержка, а не замена: **не полагайтесь на системный промпт для исправления некачественных пользовательских запросов**. Качественные пользовательские промпты всегда являются первой линией обороны против галлюцинаций.

## Примеры из практики 

**Хороший промпт:**
- Системный: «Ты — лаконичный, основанный на фактах AI-ассистент.»
- Пользовательский: «Для аудита соответствия укажи 3 требования GDPR, связанные с хранением логов, в виде пунктов списка.»
- Результат: точный, монотематический, фактический вывод.

**Плохой промпт:**
- Системный: «Ты — многоязычный эксперт в юриспруденции, программировании и юморе.»
- Пользовательский: «Напиши Python-скрипт для логирования по GDPR, объясни GDPR ребёнку и закончи анекдотом про юристов.»
- Результат: галлюцинации, путаная структура, ошибки или пропуски.

**В сложных пайплайнах (например, генерация документов или юридических кодов), пользовательский процесс делят на шаги:**
1. Сбор фактов
2. Применение нормы/скрипта
3. Форматирование и проверка вывода

Каждый шаг может быть отдельным вызовом LLM или независимым микросервисом.

## Частые ошибки

- **Политематические запросы**: галлюцинации и помехи неизбежно растут — разбивайте их.
- **Недостаточная спецификация вывода**: расплывчатые указания («суммируй») приводят к непоследовательности. Уточняйте детали — «суммируй в 3 пунктах, по 20 слов каждый».
- **Чрезмерная опора на системный промпт**: защитные рамки не спасают от двусмысленных пользовательских запросов.
- **Пропуск пост-обработки**: всегда добавляйте контроль ошибок и валидацию (поиск, семантическое сравнение, факт-чекинг) в продакшн-сценариях.

## Главный инсайт

Относитесь к LLM как к высокопроизводительному монотематическому сопоставителю паттернов, а не как к «соединителю» задач. Грамотно организованное проектирование промптов с чётким разделением ролей системных и пользовательских промптов резко снижает количество галлюцинаций и обеспечивает устойчивое качество вывода в реальных приложениях.
