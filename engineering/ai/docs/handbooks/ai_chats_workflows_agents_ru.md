# Паттерны использования LLM: Чаты, рабочие процессы и агенты в ИИ

---

Владелец: Вадим Рудаков, lefthand67@gmail.com  
Версия: 0.1.0

---

Большие языковые модели (Large Language Models, LLMs) преобразовали то, как мы создаем приложения на основе ИИ. Но для проектирования эффективных AI-систем инженеры должны понимать **теоретические и практические различия** между тремя фундаментальными паттернами использования:

- **Чаты (Chats)**
- **Рабочие процессы (Workflows)**
- **Агенты (Agents)**

Это руководство чётко и практично разбирает эти концепции, давая вам возможность выбрать правильную архитектуру для вашего следующего AI-проекта.

## I. Чат, Рабочий процесс, Агент

### 1. Что такое Чат?

#### Теоретический взгляд

**Чат** (Chat) — это в первую очередь интерактивное взаимодействие: AI-модель напрямую отвечает на пользовательский ввод выходными данными на естественном языке. Он фокусируется на понимании намерения и генерации связного, контекстно-зависимого текста.

- Чат является **реактивным**: ожидает пользовательский ввод и отвечает на него.
- Взаимодействие обычно представляет собой **одиночный или многошаговый диалог**.
- Поведение управляется **инженерией промптов (prompt engineering)**.

#### Практическая реализация

- Обычно реализуется как одиночный вызов LLM, обёрнутый некоторой логикой управления контекстом разговора.
- Может быть встроен в чат-боты, системы поддержки клиентов или интерфейсы помощников.
- Код на Python в основном управляет историей промптов и лимитами токенов.

**Пример:** Чат-бот службы поддержки, отвечающий на вопросы о продукте.

### 2. Что такое Рабочий процесс?

#### Теоретический взгляд

**Рабочий процесс** (Workflows) - это заранее заданная последовательность шагов, где LLM выполняет отдельные задачи (например, классификацию или суммаризацию) в рамках общего, управляемого кодом алгоритма.

- Состоит из **последовательных или условных шагов**.
- Каждый шаг решает **конкретную подзадачу**, такую как классификация, суммаризация или извлечение данных.
- Процесс является **детерминированным и скриптованным** инженерами-людьми.

> **Примечание:** Хотя рабочие процессы могут включать условное ветвление и обработку ошибок, которые выглядят динамически, их логика принятия решений полностью прописана инженерами-людьми. Это означает, что рабочие процессы детерминированы и лишены подлинной автономности — они не адаптируются и не пересматривают планы на основе понимания ситуации за пределами предопределённых правил.

#### Практическая реализация

- Реализуется как **Python-скрипты или оркестрируемые конвейеры**.
- Создается либо с помощью специальных инструментов (напр., LangChain), либо вручную, через написание кода, который объединяет несколько вызовов LLM в цепочку.
- Этот код контролирует, как данные передаются между этапами, что делать при ошибках и как работать, если какой-то сервис недоступен (использовать fallback).

Простыми словами: Вы пишете сценарий вида "сначала выполни это, затем передай результат туда, и если во втором шаге ошибка — сделай вот это".

**Пример:** Система скрининга резюме, которая извлекает навыки, оценивает релевантность, а затем генерирует сводный отчёт.

### 3. Что такое Агент?

#### Теоретический взгляд

Агенты (Agents) — это **автономные AI-системы**, которые воспринимают входные данные из окружения, планируют действия, динамически выбирают и выполняют задачи, а также адаптируются на основе контекста.

> Термин "агент" охватывает множество архитектур ИИ. В современных фреймворках агенты обычно состоят из модели "планировщика-исполнителя" (planner-executor model), где рассуждения о следующих действиях отделены от фактического вызова инструментов и исполнения. Это разделение помогает реализовать действительно автономные, адаптивные системы, выходящие за рамки простой скриптовой автоматизации.

Агент:

- **Думает и действует:** Система использует LLM, чтобы решить, что делать, и затем выполняет это, используя инструменты или API (например, поиск в базе данных или отправку email).
- **Самостоятельно принимает решения:** Анализирует результат каждого своего шага и сама решает, что делать дальше.
- **Учится на ошибках:** Если что-то пошло не так, система может вернуться назад, переосмыслить задачу и попробовать другой способ её решения.

В сложных агентских архитектурах уровни рассуждения и управления часто разделены. 
- Компонент планировщика (planner), обычно LLM, генерирует высокоуровневый план принятия решений на основе целей и контекста. 
- Тем временем система-исполнитель (executor) выполняет конкретные действия. В её роли может выступать как тот же или другой экземпляр LLM (для языковых подзадач), так и внешние инструменты — код, вызывающий API, базы данных или другие программы. Исполнитель отвечает за реализацию плана: вызов нужных функций, управление инструментами и поддержание состояния системы.

#### Практическая реализация

- Реализуется как сложные программные архитектуры, интегрирующие LLM с внешними API, базами данных и инструментами.
- Использует логику управления потоком выполнения вместе с вызовами моделей.
- Примеры: LangChain Agents, OpenAI function-calling agents, multi-agent systems.

**Пример:** Виртуальный помощник, который планирует поездку, запрашивая погоду, бронируя авиабилеты и динамически обновляя маршрут.

### Сводка ключевых различий

| Аспект           | Чат                      | Рабочий процесс                             | Агент                                       |
|------------------|--------------------------|---------------------------------------------|---------------------------------------------|
| **Цель**         | Человеко-подобный диалог | Структурированные многошаговые задачи       | Автономное планирование и выполнение задач  |
| **Архитектура**  | Одиночное взаимодействие с LLM | Фиксированный конвейер модульных шагов      | Динамический поток управления с инструментами и API |
| **Автономность** | Низкая; реактивная       | Средняя; скриптованный процесс              | Высокая; адаптивная и самоуправляемая       |
| **Сложность**    | Простая                  | Умеренная                                   | Высокая                                     |
| **Примеры**      | Бот для FAQ              | Конвейер суммаризации документов            | AI-помощник, бронирующий поездки            |

### Практические советы для AI-инженеров

1. **Начните с чатов**, если ваша задача — простое диалоговое ИИ.
1. **Используйте рабочие процессы** для автоматизации чётко определённых многошаговых AI-задач, где вы можете указать последовательность.
1. **Создавайте агентов**, когда вашей системе нужно автономно планировать, выбирать инструменты и адаптироваться на основе сложных контекстов.
1. Python и инженерия промптов — это основа для всех трёх подходов, но проектирование агентов требует работы с **интеграцией инструментов, логикой принятия решений и управлением состоянием**.
1. Фреймворки, такие как **LangChain**, помогают ускорить разработку рабочих процессов и агентов, предоставляя переиспользуемые компоненты.
1. Продвинутые агенты, предназначенные для промышленной эксплуатации, требуют наличия сильных механизмов оценки и наблюдаемости (observability). К ним относятся 
	- петли обратной связи для непрерывного обучения, 
	- защитные ограничения (guardrails), такие как sandboxed выполнение инструментов, и, 
	- опционально, контрольные точки с участием человека (human-in-the-loop) для обеспечения безопасности, корректности и соответствия требованиям при автономном принятии решений.

### Примеры кода

#### Чат (Python + Промпт)

```python
user_input = "Каковы преимущества солнечной энергии?"
prompt = f"Ответь в дружелюбном тоне: {user_input}"
response = llm.call(prompt)
print(response)
```

#### Рабочий процесс (Связанные шаги)

```python
def extract_topics(text):
    return llm.call(f"Извлеки основные темы из: {text}")

def summarize(topics):
    return llm.call(f"Напиши summary на основе: {topics}")

business_question = "Объясни тренды в возобновляемой энергетике."
topics = extract_topics(business_question)
summary = summarize(topics)
print(summary)
```

#### Агент (Решение + Вызов инструмента)

```python
class Agent:
    def __init__(self, tools, llm):
        self.tools = tools  # Доступные инструменты: {'weather_api': функция, 'calendar': функция, ...}
        self.llm = llm
        self.context = []  # История выполнения для контекста

    def act(self, user_goal):
        """Основной цикл принятия решений агентом"""
        max_steps = 5  # Защита от бесконечного цикла
        current_goal = user_goal
        
        for step in range(max_steps):
            # 1. ДИНАМИЧЕСКИЙ ВЫБОР ДЕЙСТВИЯ: LLM решает, что делать дальше
            action_decision = self.llm.call(f"""
                Цель: {current_goal}
                Контекст: {self.context}
                Доступные инструменты: {list(self.tools.keys())}
                
                Выбери следующее действие и обоснуй:
                1. Какой инструмент использовать?
                2. Какие параметры ему передать?
                3. Почему это приблизит нас к цели?
            """)
            
            # 2. ВЫПОЛНЕНИЕ ДЕЙСТВИЯ
            tool_name = action_decision.selected_tool
            tool_params = action_decision.parameters
            
            print(f"Шаг {step+1}: Исполняю {tool_name} с параметрами {tool_params}")
            result = self.tools[tool_name](**tool_params)
            
            # 3. СОХРАНЕНИЕ КОНТЕКСТА
            self.context.append({
                'step': step,
                'action': tool_name,
                'params': tool_params,
                'result': result
            })
            
            # 4. ПРОВЕРКА УСПЕХА И АДАПТАЦИЯ
            success_check = self.llm.call(f"""
                Исходная цель: {user_goal}
                Текущий результат: {result}
                История действий: {self.context}
                
                Достигнута ли цель? Если нет - что делать дальше?
            """)
            
            if success_check.goal_achieved:
                return self._compile_final_result()
            else:
                # Агент адаптирует подход на основе результатов
                current_goal = success_check.refined_goal
                
        return "Достигнут лимит шагов, цель не достигнута полностью"

    def _compile_final_result(self):
        """Формирование финального ответа на основе всей истории выполнения"""
        return self.llm.call(f"На основе истории {self.context} составь итоговый ответ пользователю")

# Определим несколько инструментов
def get_weather(location, date):
    return f"Погода в {location} на {date}: 25°C, солнечно"

def check_calendar(date):
    return f"На {date} в календаре свободно"
    
# другие инструменты
...

# Создаем агента
llm = SimpleLLM()
agent = Agent(tools={
    'get_weather': get_weather,
    'check_calendar': check_calendar
}, llm=llm)

# Агент САМ решит, какие инструменты использовать и в каком порядке
result = agent.act("Запланируй мероприятие на открытом воздухе на следующей неделе")
print(result)
```

***

## II. Выбор размера модели для чатов, рабочих процессов и агентов

Размер Большой языковой модели (LLM) влияет на её производительность, требования к ресурсам и пригодность для конкретных приложений. Размеры моделей обычно измеряются в миллиардах параметров (B), причём более крупные модели, как правило, предлагают более глубокое понимание, лучшее рассуждение и более нюансированные выходные данные — ценой большего количества вычислений для вывода (inference compute), памяти и хранилища.

### 1. Чаты: Малые и средние модели (1B до 7B–13B параметров)

- **Вариант использования**: Интерактивные беседы, простые вопросы-ответы, FAQ и лёгкие творческие задачи.
- **Рекомендуемые размеры**:
  - Малые модели (1B, 3B параметров) хорошо работают на мобильных и периферийных (edge) устройствах для быстрого чата с низкой задержкой.
  - Средние модели (7B до 13B) представляют собой хороший баланс для чат-ботов общего назначения, предлагая беглость речи и удержание контекста.
- **Почему**: Чатам редко требуется сложное рассуждение или тяжелая многозадачность, поэтому предпочтительны меньшие, эффективные модели, чтобы обеспечить отзывчивость без дорогой инфраструктуры.
- **Примеры включают**: Модели с 7B параметрами, работающие локально, или облачные API для чат-ботов.

### 2. Рабочие процессы: Средние и крупные модели (7B до 33B+ параметров)

- **Вариант использования**: Многошаговые процессы, требующие суммаризации, классификации или генерации структурированных выходных данных в рамках предопределённых конвейеров.
- **Рекомендуемые размеры**:
  - Модели на 7B достаточно для многих задач по извлечению текста и простых шагов рабочиз процессов.
  - Более крупные модели (13B до 33B) предпочтительны для более нюансированных или многодоменных процессов, требующих лучшего понимания или специализированных задач.
- **Почему**: Рабочие процессы часто требуют более точного и глубокого понимания, но модульность задач позволяет распределять ресурсы, фокусируясь на критических точках, что позволяет выборочно использовать более крупные модели.
- **Примеры**: Многошаговая обработка документов, автоматизированная генерация отчётов или конвейеры преобразования данных.

### 3. Агенты: Крупные и экстра-крупные модели (33B+ до 70B+ параметров)

- **Вариант использования**: Автономные системы, требующие планирования, динамического вызова инструментов, контекстной адаптации и сложного многошагового принятия решений.
- **Рекомендуемые размеры**:
  - Крупные модели, начиная с 33B+ параметров, для более богатого рассуждения и многомодальных входных данных.
  - Модели 70B+ или даже больше необходимы для продвинутых контекстов, более глубокой контекстной осведомлённости и высокой надёжности.
- **Почему**: Агентам требуется высокая ёмкость для принятия решений, обучения на основе итеративной обратной связи и гибкого поведения во многих доменах, что выигрывает от большего размера и сложности.
- **Примеры**: Виртуальные AI-помощники, оркестрирующие API, автономные исследовательские ассистенты или multi-agent системы, взаимодействующие с разнообразными внешними инструментами.

### Практические соображения по ресурсам

| Размер модели | Параметры (млрд) | Типичные требования к оборудованию          | Подходит для                          |
|---------------|------------------|---------------------------------------------|---------------------------------------|
| Малый         | 1B–3B            | ~8 GB RAM, низкие вычисления, edge/mobile  | Лёгкие чаты, быстрые ответы          |
| Средний       | 7B–13B           | 16–32 GB RAM, потребительские GPU          | Общие чаты, большинство workflow     |
| Крупный       | 33B+             | 64+ GB RAM, мощные GPU или облачная инфраструктура | Сложные workflow, агенты среднего уровня |
| Экстра-крупный| 70B+             | 72+ GB RAM, high-end GPU, распределённые системы | Продвинутые агенты, высокая автономность |

### Сводная таблица: Размер модели для каждого AI-метода

| AI-метод  | Рекомендуемый размер модели | Ключевая причина                          | Пример использования                           |
|-----------|-----------------------------|-------------------------------------------|-----------------------------------------------|
| Чат       | 1B – 13B                    | Быстрое, эффективное взаимодействие       | Мобильный чат-бот, поддержка клиентов        |
| Рабочий процесс  | 7B – 33B+                   | Сильный вывод по определённым шагам       | Конвейеры обработки документов               |
| Агент     | 13B – 70B+                  | Сложное рассуждение, работа с множеством инструментов | Виртуальные помощники с динамическим планированием |

### Итоговый совет по размеру модели

- Начните с самой маленькой модели, которая удовлетворяет вашим потребностям в производительности, чтобы сэкономить вычисления и стоимость.
- Следите за точностью и качеством ответа; увеличивайте размер моделей, если требуется более глубокое понимание или принятие решений.
- Для высоко автономных агентов выделяйте инфраструктуру для очень крупных моделей или используйте ансамблевые подходы (ensemble approaches).
- Используйте гибридные архитектуры, чтобы комбинировать малые модели в рабочих процессах с крупными моделями для стратегических точек принятия решений.

> **Примечание:** Малые или средние модели могут служить эффективными компонентами контроллера или маршрутизатора (controller or router components) в гибридных системах. Например, малая модель может определять, какую крупную специализированную LLM вызвать или выбрать определённую ветку рабочего процесса, оптимизируя вычислительные ресурсы при сохранении отзывчивости.

---

## Резюме

Понимание чатов, рабочих процессов и агентов помогает вам

- Выбирать правильную AI-архитектуру
- Строить масштабируемые и сопровождаемые AI-системы
- Эффективно использовать LLM в сочетании с управлением на Python
