# **Аналитический отчет: юридические и комплаенс-риски использования LLM в стартапе на территории РФ**
---

Владелец: Гоман Никита, nikitagoman3@gmail.com  
Версия: 0.1.0
---

## **1. Общие юридические и комплаенс-факторы**

### **1.1. Санкционное давление**
- Запрет на использование ПО/ИИ из стран, подвергшихся санкциям (США, ЕС).
- Ограничения на передачу данных в санкционные юрисдикции.
- Запрет на использование ИИ в целях, связанных с военной продукцией или нарушением законодательства РФ.

### **1.2. Требования ФСТЭК/ФСБ**
- Обязательная сертификация ПО по требованиям безопасности (ФЗ-187).
- Обработка персональных данных в РФ (ФЗ-152).
- Локализация данных и ИТ-инфраструктуры (при необходимости).

### **1.3. Интеллектуальная собственность**
- Необходимость соблюдения условий лицензий.
- Риск нарушения авторских прав при генерации ИИ-контента.

---

## **2. Сравнительная таблица LLM-моделей**

| Модель | Тип лицензии | Юридические риски | Комплаенс-риски | Возможные сценарии использования | Примечание |
|--------|--------------|-------------------|------------------|-----------------------------------|------------|
| **OpenAI GPT-4 / ChatGPT** | Proprietary | Санкции (США), передача данных за пределы РФ | Несоответствие ФЗ-152, ФЗ-187 | Запрещено использовать в РФ | Запрещено в РФ |
| **Google Gemini / PaLM 2** | Proprietary | Санкции (США), передача данных | Несоответствие ФЗ-152, ФЗ-187 | Запрещено использовать в РФ | Запрещено в РФ |
| **Meta Llama 2 / Llama 3** | Meta License (ограничения на военное использование) | Санкции, но open-weight | Не соответствует ФСТЭК, если не адаптирован | Обучение, исследование, ограниченное коммерческое | Требует локализации и аудита |
| **Anthropic Claude** | Proprietary | Санкции (США), передача данных | Несоответствие ФЗ-152, ФЗ-187 | Запрещено использовать в РФ | Запрещено в РФ |
| **Yandex GPT** | Proprietary (РФ) | Нет санкционных ограничений | Соответствует ФЗ-152, ФЗ-187 при использовании на российских ИС | Контент-генерация, аналитика, чат-боты | Рекомендовано для РФ |
| **Sber NLP / Salute** | Proprietary (РФ) | Нет санкционных ограничений | Соответствует ФСТЭК, ФЗ-152 | Контент-генерация, поддержка, аналитика | Рекомендовано для РФ |
| **Kandinsky (Сбер)** | Proprietary (РФ) | Нет санкционных ограничений | Соответствует ФСТЭК | Генерация изображений, интеграции | Рекомендовано для РФ |
| **Russian Open Source (RuGPT, Т5-ru)** | Open Source / MIT-like | Нет санкционных рисков | Требуется аудит соответствия ФСТЭК | Обучение, исследования, внутренние продукты | Рекомендовано, при соблюдении условий безопасности |
| **NVIDIA NeMo / TensorRT-LLM** | Proprietary + SDK | Санкции (США), передача данных | Не соответствует ФСТЭК автоматически | Ограничено для РФ | Запрещено или ограничено |
| **Hugging Face (open-weight модели)** | Разные (зависит от модели) | Риск нарушения ИС, передача данных | Не соответствует ФСТЭК автоматически | Только с локальной инфраструктурой, с аудитом | Возможен при соблюдении условий |

---

## **3. Возможность локального развертывания зарубежных моделей**

- **Локальное развертывание зарубежных LLM (GPT, Claude и др.) — запрещено.**
- **Развертывание open-weight моделей (Llama, Falcon и др.) — возможно, но с юридическими и комплаенс-ограничениями.**
- **Рекомендуется использовать только российские или локализованные open-source модели, прошедшие внутреннюю проверку на соответствие ФСТЭК.**

---

## **4. Примеры open-source моделей с Hugging Face, подходящих под ограничения РФ**

| Модель | Тип лицензии | Мощность (параметры) | Требуемое оборудование | Кол-во операций (FLOPs) | Назначение | Комплаенс-ограничения |
|--------|--------------|----------------------|--------------------------|--------------------------|------------|------------------------|
| **RuGPT-3Large** | MIT | 760M | 1x GPU (16GB VRAM) | ~1.5 TFLOPs (на 1 токен) | Текстовая генерация, чат-боты, аналитика | Нет (российская модель) |
| **Falcon-7B** | Apache 2.0 | 7B | 1x GPU (24GB VRAM) | ~14 TFLOPs (на 1 токен) | Общее назначение, Q&A, генерация | Требует аудит |
| **Mistral-7B** | Apache 2.0 | 7B | 1x GPU (24GB VRAM) | ~14 TFLOPs (на 1 токен) | Код, генерация, инструкции | Требует аудит |
| **LLaMA-2-7B** | Meta License | 7B | 1x GPU (24GB VRAM) | ~14 TFLOPs (на 1 токен) | Общее назначение, обучение | Ограничения на коммерч. использование |
| **OpenLLaMA-7B** | Apache 2.0 | 7B | 1x GPU (24GB VRAM) | ~14 TFLOPs (на 1 токен) | Образование, исследование | Требует аудит |

---

## **5. Рекомендации для стартапа**

1. **Приоритет:**
   - Использование российских LLM (Yandex GPT, Сбер Salute).
   - Open-source модели, адаптированные под требования ФСТЭК.

2. **Юридические меры:**
   - Обеспечить локализацию данных в РФ.
   - Пройти оценку соответствия ПО требованиям ФСТЭК/ФСБ.
   - Вести аудит генерации контента.

3. **Технические меры:**
   - Использовать изолированные инфраструктуры.
   - Обновлять модели только из локальных репозиториев.

---

## **6. Вывод**

Для стартапа, работающего на территории РФ, **юридически безопасными** являются:
- Российские LLM (Yandex GPT, Сбер Salute).
- Локализованные open-source модели, соответствующие требованиям ФСТЭК.

**Запрещено использовать** LLM, разработанные в санкционных юрисдикциях (США, ЕС).  
**Развертывание зарубежных LLM локально — запрещено.**  
**Open-source модели — возможны при соблюдении условий лицензии и прохождении аудита.**